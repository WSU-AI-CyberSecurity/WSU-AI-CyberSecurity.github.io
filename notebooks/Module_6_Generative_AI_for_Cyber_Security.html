
<!DOCTYPE html>


<html lang="en" data-content_root="../" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Module 6: Generative AI for Cyber Security &#8212; WSU ML in Cybersecurity</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=c72df8c4" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=afe5de03"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/Module_6_Generative_AI_for_Cyber_Security';</script>
    <script src="../_static/custom.js?v=a4c55d5e"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Module 5: Anomaly and Intrusion Detection with Machine Learning" href="Module_5_Anomaly_and_Intrusion_Detection_with_Machine_Learning.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="WSU ML in Cybersecurity - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="WSU ML in Cybersecurity - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Exploring Machine Learning in Cybersecurity Workshop
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Module_0_Introduction_to_Jupyter_Notebook_and_Colab.html"><strong>Module 0:</strong> Introduction to Jupyter Notebook and Colab</a></li>



<li class="toctree-l1"><a class="reference internal" href="Module_1_Fundamentals_of_Machine_Learning.html"><strong>Module 1:</strong> Fundamentals of Machine Learning</a></li>

<li class="toctree-l1"><a class="reference internal" href="Module_2_Supervised_learning.html"><strong>Module 2:</strong> Supervised Learning</a></li>




<li class="toctree-l1"><a class="reference internal" href="Module_3_Data_preprocessing_and_features_selection.html"><strong>Module 3:</strong> Data Preprocessing and Features Selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="Module_4_Unsupervised_Learning.html"><strong>Module 4</strong>: Unsupervised Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="Module_5_Anomaly_and_Intrusion_Detection_with_Machine_Learning.html"><strong>Module 5:</strong> Anomaly and Intrusion Detection with Machine Learning</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>Module 6:</strong> Generative AI for Cyber Security</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/WSU-AI-CyberSecurity/WSU-AI-CyberSecurity.github.io/blob/main/notebooks/Module_6_Generative_AI_for_Cyber_Security.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/notebooks/Module_6_Generative_AI_for_Cyber_Security.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Module 6: Generative AI for Cyber Security</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tunning-a-model-for-cyber-security">Fine-tunning a model for Cyber Security</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-securebret">Case Study: SecureBret</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-llms-as-offensive-generative-ai">Using LLMs as Offensive Generative AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#offensive-generative-ai-model">Offensive Generative AI Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-model-for-cracking-password">Generative model for cracking password</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#passgpt">PassGPT</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-the-behaviour-of-human-s-password-creation">Learning the behaviour of human’s password creation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-password-generation">Conditional Password Generation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defensive-generative-ai">Defensive Generative AI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#detecting-deepfake">Detecting Deepfake</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#let-s-try-some-images-from-popular-meme">Let’s try some images from popular meme</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="module-6-generative-ai-for-cyber-security">
<h1><strong>Module 6:</strong> Generative AI for Cyber Security<a class="headerlink" href="#module-6-generative-ai-for-cyber-security" title="Link to this heading">#</a></h1>
<section id="fine-tunning-a-model-for-cyber-security">
<h2>Fine-tunning a model for Cyber Security<a class="headerlink" href="#fine-tunning-a-model-for-cyber-security" title="Link to this heading">#</a></h2>
<p>Fine-tuning a language model in the context of LLMs (Masked Language Models like BERT), refers to the process of taking a pre-trained language model and further training it on a smaller, task-specific dataset to adapt it to a specific downstream task. The idea is to leverage the knowledge learned during the initial pre-training on a large corpus and then fine-tune the model to perform well on a specific task of interest.</p>
<ol class="arabic">
<li><p><strong>Pre-training on a Large Corpus</strong></p>
<p>Initially, the language model is pre-trained on a large and diverse dataset. During this phase, the model learns general language patterns, syntax, and contextual relationships between words.</p>
</li>
<li><p><strong>Task-Specific Data</strong></p>
<p>After pre-training, the model is fine-tuned on a smaller dataset that is specific to the task you want the model to perform well on. This dataset is typically labeled and consists of examples relevant to the downstream task.</p>
</li>
<li><p><strong>Architecture and Parameters</strong></p>
<p>The architecture of the model remains the same, but the parameters learned during pre-training are further adjusted based on the task-specific data. The fine-tuning process updates the weights of the model to make it more suited for the specific task.</p>
</li>
<li><p><strong>Task-Specific Objective Function</strong></p>
<p>The objective function used during fine-tuning is tailored to the downstream task. For example, in classification tasks, the model might be fine-tuned using a cross-entropy loss function.</p>
</li>
<li><p><strong>Learning Rate and Training Hyperparameters</strong></p>
<p>Fine-tuning often involves adjusting the learning rate and other hyperparameters to ensure effective training on the smaller dataset. This helps prevent overfitting and encourages the model to adapt to the specific task.</p>
</li>
<li><p><strong>Transfer of Knowledge</strong></p>
<p>The knowledge gained during pre-training, such as understanding of language structures and semantics, is transferred to the task-specific model. Fine-tuning allows the model to specialize without losing the general language understanding acquired during pre-training.</p>
</li>
</ol>
<p><img alt="" src="https://www.labellerr.com/blog/content/images/2023/08/Fine-tune-example.png" /></p>
<p>Fine-tuning is particularly useful when you have a limited amount of task-specific data. By starting with a pre-trained model, you can benefit from the knowledge embedded in the model and fine-tune it to achieve good performance on your specific task, even with a smaller dataset. This approach has been successful in various natural language processing (NLP) tasks, ranging from sentiment analysis to named entity recognition.</p>
</section>
<section id="case-study-securebret">
<h2>Case Study: SecureBret<a class="headerlink" href="#case-study-securebret" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/pdf/2204.02685">SecureBERT</a> is a domain-specific language model to represent cybersecurity textual data which is trained on a large amount of in-domain text crawled from online resources.</p>
<p>SecureBERT can be used as the base model for any downstream task including text classification, NER, Seq-to-Seq, QA, etc.</p>
<ul class="simple">
<li><p>SecureBERT has demonstrated significantly higher performance in predicting masked words within the text when compared to existing models like RoBERTa (base and large), SciBERT, and SecBERT.</p></li>
<li><p>SecureBERT has also demonstrated promising performance in preserving general English language understanding (representation).</p></li>
</ul>
<p><img alt="" src="https://user-images.githubusercontent.com/46252665/195998237-9bbed621-8002-4287-ac0d-19c4f603d919.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>transformers
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>torch
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>tokenizers
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: transformers in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (4.23.0)
Requirement already satisfied: filelock in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from transformers) (3.13.1)
Requirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.10.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from transformers) (0.20.2)
Requirement already satisfied: numpy&gt;=1.17 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from transformers) (1.26.3)
Requirement already satisfied: packaging&gt;=20.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from transformers) (23.2)
Requirement already satisfied: pyyaml&gt;=5.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from transformers) (6.0.1)
Requirement already satisfied: regex!=2019.12.17 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from transformers) (2023.12.25)
Requirement already satisfied: requests in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from transformers) (2.31.0)
Requirement already satisfied: tokenizers!=0.11.3,&lt;0.14,&gt;=0.11.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from transformers) (0.13.3)
Requirement already satisfied: tqdm&gt;=4.27 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from transformers) (4.66.1)
Requirement already satisfied: fsspec&gt;=2023.5.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from huggingface-hub&lt;1.0,&gt;=0.10.0-&gt;transformers) (2023.10.0)
Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from huggingface-hub&lt;1.0,&gt;=0.10.0-&gt;transformers) (4.9.0)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from requests-&gt;transformers) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from requests-&gt;transformers) (3.6)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from requests-&gt;transformers) (2.2.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from requests-&gt;transformers) (2023.11.17)
Requirement already satisfied: torch in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (2.2.0)
Requirement already satisfied: filelock in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (3.13.1)
Requirement already satisfied: typing-extensions&gt;=4.8.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (4.9.0)
Requirement already satisfied: sympy in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (1.12)
Requirement already satisfied: networkx in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (3.2.1)
Requirement already satisfied: jinja2 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (3.1.3)
Requirement already satisfied: fsspec in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (2023.10.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (2.19.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (12.1.105)
Requirement already satisfied: triton==2.2.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch) (2.2.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch) (12.3.101)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from jinja2-&gt;torch) (2.1.5)
Requirement already satisfied: mpmath&gt;=0.19 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from sympy-&gt;torch) (1.3.0)
Requirement already satisfied: tokenizers in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (0.13.3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RobertaTokenizer</span><span class="p">,</span> <span class="n">RobertaModel</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RobertaTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;ehsanaghaei/SecureBERT&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RobertaModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;ehsanaghaei/SecureBERT&quot;</span><span class="p">)</span>

<span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;This is SecureBERT!&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">inputs</span><span class="p">)</span>

<span class="n">last_hidden_states</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">last_hidden_state</span>


<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RobertaTokenizer</span><span class="p">,</span> <span class="n">RobertaTokenizerFast</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RobertaTokenizerFast</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;ehsanaghaei/SecureBERT&quot;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">RobertaForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;ehsanaghaei/SecureBERT&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">predict_mask</span><span class="p">(</span><span class="n">sent</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">topk</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">print_results</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">token_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">sent</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
    <span class="n">masked_position</span> <span class="o">=</span> <span class="p">(</span><span class="n">token_ids</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">mask_token_id</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span>
    <span class="n">masked_pos</span> <span class="o">=</span> <span class="p">[</span><span class="n">mask</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">mask</span> <span class="ow">in</span> <span class="n">masked_position</span><span class="p">]</span>
    <span class="n">words</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>

    <span class="n">last_hidden_state</span> <span class="o">=</span> <span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

    <span class="n">list_of_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">mask_index</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">masked_pos</span><span class="p">):</span>
        <span class="n">mask_hidden_state</span> <span class="o">=</span> <span class="n">last_hidden_state</span><span class="p">[</span><span class="n">mask_index</span><span class="p">]</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">mask_hidden_state</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="n">topk</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">item</span><span class="p">())</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx</span><span class="p">]</span>
        <span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">]</span>
        <span class="n">list_of_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">list_of_list</span>


<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
<span class="kn">import</span> <span class="nn">html</span>


<span class="k">def</span> <span class="nf">input_masked_sentence</span><span class="p">(</span><span class="nb">input</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">escape_mask</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;&lt;mask&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;&amp;zwj;mask&gt;&quot;</span><span class="p">)</span>

    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&lt;b&gt;Input:&lt;/b&gt; </span><span class="si">{</span><span class="n">escape_mask</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">predict_mask</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&lt;b&gt;SecureBert:&lt;/b&gt; </span><span class="si">{</span><span class="s1">&#39; | &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Some weights of the model checkpoint at ehsanaghaei/SecureBERT were not used when initializing RobertaModel: [&#39;lm_head.layer_norm.weight&#39;, &#39;lm_head.dense.bias&#39;, &#39;lm_head.layer_norm.bias&#39;, &#39;lm_head.bias&#39;, &#39;lm_head.dense.weight&#39;]
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at ehsanaghaei/SecureBERT and are newly initialized: [&#39;roberta.pooler.dense.weight&#39;, &#39;roberta.pooler.dense.bias&#39;]
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">&lt;mask&gt;</span></code> token is commonly used in the context of masked language models (LLMs) or masked language model pre-training. This approach is a type of unsupervised learning where a model is trained to predict missing or masked tokens in a sequence of text. The <code class="docutils literal notranslate"><span class="pre">&lt;mask&gt;</span></code> token is used to represent the positions in the input text where tokens are masked or hidden during training.</p>
<p>Here’s a general overview of how the <code class="docutils literal notranslate"><span class="pre">&lt;mask&gt;</span></code> token works in the context of LLMs:</p>
<p><strong>Masking during Training:</strong></p>
<p>During the pre-training phase, a certain percentage of tokens in the input text are randomly selected to be masked. These masked tokens are then replaced with the <code class="docutils literal notranslate"><span class="pre">&lt;mask&gt;</span></code> token.
The model is trained to predict the original identity of the masked tokens based on the context provided by the surrounding tokens.
Objective Function:</p>
<p>The objective function during training is typically to maximize the likelihood of predicting the correct tokens at the masked positions.
This training process helps the model learn contextual relationships and dependencies between words in a given language.</p>
<p><img alt="" src="https://user-images.githubusercontent.com/46252665/195998153-f5682f7c-60a8-486d-b2c1-9ef5732c24ba.png" /></p>
<p><strong>Fine-Tuning and Downstream Tasks:</strong></p>
<p>After pre-training, the model can be fine-tuned on specific downstream tasks (such as text classification, named entity recognition, etc.).
The knowledge gained during pre-training helps the model perform well on a range of natural language processing (NLP) tasks.
Prediction during Inference:</p>
<p>During inference or when using the model for downstream tasks, the <code class="docutils literal notranslate"><span class="pre">&lt;mask&gt;</span></code> token can be used to predict missing tokens in a given sequence. For example, if you provide a sentence with some tokens replaced by <code class="docutils literal notranslate"><span class="pre">&lt;mask&gt;</span></code>, the model can predict the most likely tokens for those masked positions.
Overall, the <code class="docutils literal notranslate"><span class="pre">&lt;mask&gt;</span></code> token is a key element in the training process of LLMs, enabling them to learn rich representations of language and perform well on a variety of NLP tasks. The most well-known model that uses this approach is BERT (Bidirectional Encoder Representations from Transformers).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_masked_sentence</span><span class="p">(</span>
    <span class="s2">&quot;Adversaries may also compromise sites then include &lt;mask&gt; content designed to collect website authentication cookies from visitors.&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Input:</b> Adversaries may also compromise sites then include <&zwj;mask> content designed to collect website authentication cookies from visitors.</div><div class="output text_html"><b>SecureBert:</b> malicious | JavaScript | phishing | iframe | dynamic | additional | downloadable | hostile | embedded | website</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_masked_sentence</span><span class="p">(</span>
    <span class="s2">&quot;One example of this is MS14-068, which targets &lt;mask&gt; and can be used to forge Kerberos tickets using domain user permissions.&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Input:</b> One example of this is MS14-068, which targets <&zwj;mask> and can be used to forge Kerberos tickets using domain user permissions.</div><div class="output text_html"><b>SecureBert:</b> Kerberos | authentication | users | Windows | administrators | LDAP | PAM | Samba | NTLM | AD</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_masked_sentence</span><span class="p">(</span><span class="s2">&quot;Paris is the &lt;mask&gt; of France.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Input:</b> Paris is the <&zwj;mask> of France.</div><div class="output text_html"><b>SecureBert:</b> capital | Republic | Government | province | name | city | government | language | Capital | Bank</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_masked_sentence</span><span class="p">(</span><span class="s2">&quot;Virus causes &lt;mask&gt;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Input:</b> Virus causes <&zwj;mask>.</div><div class="output text_html"><b>SecureBert:</b> DoS | crash | reboot | reboots | panic | crashes | corruption | DOS | vulnerability | XSS</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_masked_sentence</span><span class="p">(</span><span class="s2">&quot;Sending huge amount of packets through network leads to &lt;mask&gt;.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Input:</b> Sending huge amount of packets through network leads to <&zwj;mask>.</div><div class="output text_html"><b>SecureBert:</b> DoS | congestion | crashes | crash | problems | DOS | vulnerability | failure | vulnerabilities | errors</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">input_masked_sentence</span><span class="p">(</span>
    <span class="s2">&quot;A &lt;mask&gt; injection occurs when an attacker inserts malicious code into a server&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><b>Input:</b> A <&zwj;mask> injection occurs when an attacker inserts malicious code into a server</div><div class="output text_html"><b>SecureBert:</b> code | SQL | command | malicious | script | web | vulnerability | server | ql | SQL</div></div>
</div>
</section>
<section id="using-llms-as-offensive-generative-ai">
<h2>Using LLMs as Offensive Generative AI<a class="headerlink" href="#using-llms-as-offensive-generative-ai" title="Link to this heading">#</a></h2>
</section>
<section id="offensive-generative-ai-model">
<h2>Offensive Generative AI Model<a class="headerlink" href="#offensive-generative-ai-model" title="Link to this heading">#</a></h2>
<p>Offensive security is the practice of actively seeking out vulnerabilities in an organization’s cybersecurity. It often involves using similar tactics as attackers and might include red teaming, penetration testing and vulnerability assessments. Offensive security can be shortened to “OffSec.”</p>
<p>Offensive generative AI refers natural language processing (NLP) and machine learning techniques, that are designed or trained to produce content that is offensive, harmful, or inappropriate in some way. This content could include hate speech, derogatory language, violent or threatening messages, misinformation, or other forms of harmful content. Malicious AI can weaponising generative AI to improve the monetisation of their attacks, which will stem from a surge in ransomware attacks and phishing campaigns.</p>
<p><img alt="image.png" src="https://canalys-prod-public.s3.eu-west-1.amazonaws.com/client/static/uimages/7Xb9lz2jbGfvTH1TJcfoGuID7VNqyocPICtqhesEJqerayYVsmLORCMJb1BQNSKC.png" /></p>
<p>Such AI systems can pose significant ethical and societal challenges. They have the potential to spread harmful messages at scale, amplify existing biases and prejudices present in the training data, and contribute to the proliferation of toxic online environments. Offensive generative AI can be used maliciously by individuals or groups to harass others, manipulate public opinion, or undermine trust in information sources.</p>
<section id="generative-model-for-cracking-password">
<h3>Generative model for cracking password<a class="headerlink" href="#generative-model-for-cracking-password" title="Link to this heading">#</a></h3>
<p>Generative AI poses several dangers for password cracking:</p>
<ul class="simple">
<li><p>Speed and Efficiency: Generative AI can significantly speed up the process of password cracking by generating and testing a vast number of possible passwords in a short amount of time. This can make it much more efficient for attackers to breach password-protected systems or accounts.</p></li>
<li><p>Sophisticated Attack Techniques: Generative AI can employ sophisticated techniques, such as neural networks or reinforcement learning, to generate passwords that are more likely to be successful in cracking password hashes or bypassing authentication mechanisms.</p></li>
<li><p>Adaptability: Generative AI models can adapt to different patterns and structures commonly found in passwords, such as common words, phrases, or character combinations. This adaptability makes them more effective at cracking passwords that may not be easily guessable or vulnerable to traditional brute-force methods.</p></li>
<li><p>Privacy Risks: If generative AI is used for password cracking, it could compromise the privacy and security of individuals or organizations by gaining unauthorized access to sensitive information stored behind password-protected systems or accounts.</p></li>
<li><p>Scale and Automation: Generative AI can be deployed at scale and automated, allowing attackers to launch large-scale password cracking attacks against multiple targets simultaneously, increasing the potential impact and severity of security breaches.imators.</p></li>
</ul>
</section>
<section id="passgpt">
<h3>PassGPT<a class="headerlink" href="#passgpt" title="Link to this heading">#</a></h3>
<p>PassGPT is an LLM trained on password leaks for password generation. PassGPT outperforms existing methods based <strong>by guessing twice as many previously unseen passwords</strong>. PassGPT also contains the concept of guided password generation, where they leverage PassGPT sampling procedure to generate passwords matching arbitrary constraints.</p>
<p><img alt="" src="https://raw.githubusercontent.com/WSU-AI-CyberSecurity/WSU-AI-CyberSecurity.github.io/main/assets/passgpt.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">GPT2LMHeadModel</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">RobertaTokenizerFast</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">RobertaTokenizerFast</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;javirandor/passgpt-10characters&quot;</span><span class="p">,</span>
    <span class="n">max_len</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
    <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">do_lower_case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">strip_accents</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">mask_token</span><span class="o">=</span><span class="s2">&quot;&lt;mask&gt;&quot;</span><span class="p">,</span>
    <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;&lt;unk&gt;&quot;</span><span class="p">,</span>
    <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">,</span>
    <span class="n">truncation_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">GPT2LMHeadModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;javirandor/passgpt-10characters&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">NUM_GENERATIONS</span> <span class="o">=</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">generate_password</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">12</span><span class="p">):</span>
    <span class="n">start_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span>
    <span class="n">start_token</span> <span class="o">=</span> <span class="n">start_token</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Generate passwords sampling from the beginning of password token</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">start_token</span><span class="p">]),</span>
        <span class="c1"># do_sample=True,</span>
        <span class="n">num_return_sequences</span><span class="o">=</span><span class="n">NUM_GENERATIONS</span><span class="p">,</span>
        <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
        <span class="n">bad_words_ids</span><span class="o">=</span><span class="p">[[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">]],</span>
    <span class="p">)</span>

    <span class="c1"># Remove start of sentence token</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">g</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>

    <span class="n">decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
    <span class="n">decoded_clean</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">i</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;&lt;/s&gt;&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">decoded</span>
    <span class="p">]</span>  <span class="c1"># Get content before end of password token</span>

    <span class="c1"># Print your sampled passwords!</span>
    <span class="k">return</span> <span class="n">decoded_clean</span>


<span class="n">seedgen</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="learning-the-behaviour-of-human-s-password-creation">
<h3>Learning the behaviour of human’s password creation<a class="headerlink" href="#learning-the-behaviour-of-human-s-password-creation" title="Link to this heading">#</a></h3>
<p>The following are generating the most likely password that people choose based on big data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generate_password</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;0876060007&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generate_password</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;pas&quot;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;password&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generate_password</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;qw&quot;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;qwerty&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generate_password</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;ilo&quot;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;iloveme123&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generate_password</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s2">&quot;John&quot;</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Johnny1994&#39;]
</pre></div>
</div>
</div>
</div>
<p><strong>You can also do a conditional password generation</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">string</span>

<span class="n">DEVICE</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>

<span class="c1"># Map each of the desired character groups into their corresponding ids (as given by the tokenizer)</span>
<span class="n">lowercase</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">)</span>
<span class="n">uppercase</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">ascii_uppercase</span><span class="p">)</span>
<span class="n">digits</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">digits</span><span class="p">)</span>
<span class="n">punctuation</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">)</span>

<span class="n">lowercase_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">lowercase</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="n">uppercase_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">uppercase</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="n">digits_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">digits</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
<span class="n">punctuation_tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">punctuation</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>


<span class="c1"># All possible tokens in our model</span>
<span class="n">all_tokens</span> <span class="o">=</span> <span class="p">[[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">))]</span>


<span class="k">def</span> <span class="nf">conditional_generation</span><span class="p">(</span><span class="n">template</span><span class="p">,</span> <span class="n">num_generations</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">generated</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">generations</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">while</span> <span class="n">generated</span> <span class="o">&lt;</span> <span class="n">num_generations</span><span class="p">:</span>
        <span class="n">generation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">bos_token_id</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">current_length</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">template</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">char</span> <span class="o">==</span> <span class="s2">&quot;l&quot;</span><span class="p">:</span>
                <span class="n">bad_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">all_tokens</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lowercase_tokens</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">char</span> <span class="o">==</span> <span class="s2">&quot;u&quot;</span><span class="p">:</span>
                <span class="n">bad_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">all_tokens</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">uppercase_tokens</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">char</span> <span class="o">==</span> <span class="s2">&quot;d&quot;</span><span class="p">:</span>
                <span class="n">bad_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">all_tokens</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">digits_tokens</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">char</span> <span class="o">==</span> <span class="s2">&quot;p&quot;</span><span class="p">:</span>
                <span class="n">bad_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">all_tokens</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">punctuation_tokens</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">bad_tokens</span> <span class="o">=</span> <span class="p">[[</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">]]</span>

            <span class="n">generation</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="n">generation</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">),</span>
                <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">current_length</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                <span class="n">pad_token_id</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
                <span class="n">num_return_sequences</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">bad_words_ids</span><span class="o">=</span><span class="n">bad_tokens</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">current_length</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="mi">2</span> <span class="ow">in</span> <span class="n">generation</span><span class="o">.</span><span class="n">flatten</span><span class="p">():</span>
            <span class="n">generations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">generation</span><span class="p">)</span>
            <span class="n">generated</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">generations</span><span class="p">,</span> <span class="mi">0</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">:])</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="conditional-password-generation">
<h3>Conditional Password Generation<a class="headerlink" href="#conditional-password-generation" title="Link to this heading">#</a></h3>
<p>One of the main advantages of Generative AI is the possibility of generating passwords under arbitrary constraints. In this template code, we have created five different groups of characters that we can sample from at each position:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">l</span></code>: lowercase letters</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">u</span></code>: uppercase letters</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">d</span></code>: digits</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">p</span></code>: punctuation</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">*</span></code>: any character in the vocabulary</p></li>
<li></li>
</ul>
<p>You can create any template by combining these. For example, <code class="docutils literal notranslate"><span class="pre">lllldd</span></code> will generate passwords starting with four lowercase letters and finishing with two digits.</p>
<p>Feel free to create your own character groups below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conditional_generation</span><span class="p">(</span><span class="s2">&quot;lllldd&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;owen32&#39;, &#39;will14&#39;, &#39;bubb12&#39;, &#39;rgdl15&#39;, &#39;pinc04&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conditional_generation</span><span class="p">(</span><span class="s2">&quot;u*****lldd&quot;</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;KTMRGEma12&#39;, &#39;Valenbir10&#39;, &#39;Brandonm93&#39;, &#39;Brickfor23&#39;, &#39;Bradbitc10&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>facenet_pytorch<span class="w"> </span>opencv-python<span class="w"> </span>grad-cam
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Requirement already satisfied: facenet_pytorch in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (2.5.3)
Requirement already satisfied: opencv-python in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (4.9.0.80)
Requirement already satisfied: grad-cam in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (1.5.0)
Requirement already satisfied: numpy in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from facenet_pytorch) (1.26.3)
Requirement already satisfied: requests in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from facenet_pytorch) (2.31.0)
Requirement already satisfied: torchvision in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from facenet_pytorch) (0.17.0)
Requirement already satisfied: pillow in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from facenet_pytorch) (10.2.0)
Requirement already satisfied: torch&gt;=1.7.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from grad-cam) (2.2.0)
Requirement already satisfied: ttach in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from grad-cam) (0.0.3)
Requirement already satisfied: tqdm in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from grad-cam) (4.66.1)
Requirement already satisfied: matplotlib in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from grad-cam) (3.8.2)
Requirement already satisfied: scikit-learn in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from grad-cam) (1.4.0)
Requirement already satisfied: filelock in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (3.13.1)
Requirement already satisfied: typing-extensions&gt;=4.8.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (4.9.0)
Requirement already satisfied: sympy in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (1.12)
Requirement already satisfied: networkx in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (3.2.1)
Requirement already satisfied: jinja2 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (3.1.3)
Requirement already satisfied: fsspec in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (2023.10.0)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (2.19.3)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (12.1.105)
Requirement already satisfied: triton==2.2.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from torch&gt;=1.7.1-&gt;grad-cam) (2.2.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch&gt;=1.7.1-&gt;grad-cam) (12.3.101)
Requirement already satisfied: contourpy&gt;=1.0.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from matplotlib-&gt;grad-cam) (1.2.0)
Requirement already satisfied: cycler&gt;=0.10 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from matplotlib-&gt;grad-cam) (0.12.1)
Requirement already satisfied: fonttools&gt;=4.22.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from matplotlib-&gt;grad-cam) (4.47.2)
Requirement already satisfied: kiwisolver&gt;=1.3.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from matplotlib-&gt;grad-cam) (1.4.5)
Requirement already satisfied: packaging&gt;=20.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from matplotlib-&gt;grad-cam) (23.2)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from matplotlib-&gt;grad-cam) (3.1.1)
Requirement already satisfied: python-dateutil&gt;=2.7 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from matplotlib-&gt;grad-cam) (2.8.2)
Requirement already satisfied: importlib-resources&gt;=3.2.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from matplotlib-&gt;grad-cam) (6.1.1)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from requests-&gt;facenet_pytorch) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from requests-&gt;facenet_pytorch) (3.6)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from requests-&gt;facenet_pytorch) (2.2.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from requests-&gt;facenet_pytorch) (2023.11.17)
Requirement already satisfied: scipy&gt;=1.6.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from scikit-learn-&gt;grad-cam) (1.12.0)
Requirement already satisfied: joblib&gt;=1.2.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from scikit-learn-&gt;grad-cam) (1.3.2)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from scikit-learn-&gt;grad-cam) (3.2.0)
Requirement already satisfied: zipp&gt;=3.1.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from importlib-resources&gt;=3.2.0-&gt;matplotlib-&gt;grad-cam) (3.17.0)
Requirement already satisfied: six&gt;=1.5 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from python-dateutil&gt;=2.7-&gt;matplotlib-&gt;grad-cam) (1.16.0)
Requirement already satisfied: MarkupSafe&gt;=2.0 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from jinja2-&gt;torch&gt;=1.7.1-&gt;grad-cam) (2.1.5)
Requirement already satisfied: mpmath&gt;=0.19 in /home/soraxas/micromamba/envs/wsu/lib/python3.9/site-packages (from sympy-&gt;torch&gt;=1.7.1-&gt;grad-cam) (1.3.0)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="defensive-generative-ai">
<h2>Defensive Generative AI<a class="headerlink" href="#defensive-generative-ai" title="Link to this heading">#</a></h2>
<p>After having a look at how generative AI can be destructive, let’s have a look at using AI in a more defensive manner.</p>
<p>Defensive Generative AI refers to a branch of artificial intelligence (AI) research that focuses on developing systems capable of defending against attacks targeting generative models. Generative models, such as generative adversarial networks (GANs) or variational autoencoders (VAEs), are AI architectures designed to generate new data samples that resemble a training dataset. These models have shown great potential in various applications, including image generation, text generation, and data synthesis.</p>
<p>However, like any AI system, generative models are vulnerable to attacks. Adversarial attacks against generative models can involve <strong>manipulating input data</strong> to generate outputs that mislead or compromise the model’s performance. These attacks can have significant implications, such as <strong>generating fake images</strong> that appear real or altering text generation models to produce misleading or harmful content.</p>
<p><img alt="" src="https://secureops.com/wp-content/uploads/2023/09/AI-1.jpg" /></p>
<p>Defensive Generative AI aims to develop techniques and strategies to mitigate the risks associated with adversarial attacks on generative models. This may involve developing robust training methods, designing algorithms that can detect adversarial inputs, or incorporating additional security measures into generative models to enhance their resilience against attacks.</p>
<section id="detecting-deepfake">
<h3>Detecting Deepfake<a class="headerlink" href="#detecting-deepfake" title="Link to this heading">#</a></h3>
<p><strong>Deepfake</strong> refers to a manipulated or synthesized media, typically videos or images, where a person’s likeness or voice is replaced with that of another individual using deep learning techniques, particularly generative adversarial networks (GANs) or similar deep learning architectures. The term “deepfake” is a combination of “deep learning” and “fake.”</p>
<p>Deepfakes have gained notoriety for their potential to deceive or manipulate viewers by creating realistic but entirely fabricated content. They can be used to superimpose faces onto bodies in videos, alter facial expressions or lip movements to match different audio tracks, or even create entirely synthetic videos of people saying or doing things they never actually did.</p>
<p><img alt="" src="https://www.gavstech.com/wp-content/uploads/2023/12/deepfake.png" /></p>
<p>Lets load up a model that can detects fake images by focusing on various local region on the faces.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">![</span><span class="w"> </span>-f<span class="w"> </span>examples.zip<span class="w"> </span><span class="o">]</span><span class="w"> </span><span class="o">||</span><span class="w"> </span>wget<span class="w"> </span>https://huggingface.co/spaces/aaronespasa/deepfake-detection/resolve/main/examples.zip?download<span class="o">=</span><span class="nb">true</span><span class="w"> </span>-O<span class="w"> </span>examples.zip
<span class="o">![</span><span class="w"> </span>-f<span class="w"> </span>resnetinceptionv1_epoch_32.pth<span class="w"> </span><span class="o">]</span><span class="w"> </span><span class="o">||</span><span class="w"> </span>wget<span class="w"> </span>https://huggingface.co/spaces/aaronespasa/deepfake-detection/resolve/main/resnetinceptionv1_epoch_32.pth?download<span class="o">=</span><span class="nb">true</span><span class="w"> </span>-O<span class="w"> </span>resnetinceptionv1_epoch_32.pth
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">facenet_pytorch</span> <span class="kn">import</span> <span class="n">MTCNN</span><span class="p">,</span> <span class="n">InceptionResnetV1</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">zipfile</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam</span> <span class="kn">import</span> <span class="n">GradCAM</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam.utils.model_targets</span> <span class="kn">import</span> <span class="n">ClassifierOutputTarget</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam.utils.image</span> <span class="kn">import</span> <span class="n">show_cam_on_image</span>

<span class="k">with</span> <span class="n">zipfile</span><span class="o">.</span><span class="n">ZipFile</span><span class="p">(</span><span class="s2">&quot;examples.zip&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_ref</span><span class="p">:</span>
    <span class="n">zip_ref</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>

<span class="n">DEVICE</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>

<span class="n">mtcnn</span> <span class="o">=</span> <span class="n">MTCNN</span><span class="p">(</span><span class="n">select_largest</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">post_process</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">InceptionResnetV1</span><span class="p">(</span>
    <span class="n">pretrained</span><span class="o">=</span><span class="s2">&quot;vggface2&quot;</span><span class="p">,</span> <span class="n">classify</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span>
<span class="p">)</span>

<span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
    <span class="s2">&quot;resnetinceptionv1_epoch_32.pth&quot;</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s2">&quot;model_state_dict&quot;</span><span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>InceptionResnetV1(
  (conv2d_1a): BasicConv2d(
    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (conv2d_2a): BasicConv2d(
    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (conv2d_2b): BasicConv2d(
    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (maxpool_3a): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  (conv2d_3b): BasicConv2d(
    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (conv2d_4a): BasicConv2d(
    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (conv2d_4b): BasicConv2d(
    (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
    (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
  )
  (repeat_1): Sequential(
    (0): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (1): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (2): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (3): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (4): Block35(
      (branch0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (branch2): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
  )
  (mixed_6a): Mixed_6a(
    (branch0): BasicConv2d(
      (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (branch1): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(256, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (2): BasicConv2d(
        (conv): Conv2d(192, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (repeat_2): Sequential(
    (0): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (1): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (2): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (3): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (4): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (5): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (6): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (7): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (8): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (9): Block17(
      (branch0): BasicConv2d(
        (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(256, 896, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
  )
  (mixed_7a): Mixed_7a(
    (branch0): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (branch1): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (2): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (repeat_3): Sequential(
    (0): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (1): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (2): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (3): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
    (4): Block8(
      (branch0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (branch1): Sequential(
        (0): BasicConv2d(
          (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (1): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
        (2): BasicConv2d(
          (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU()
        )
      )
      (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
      (relu): ReLU()
    )
  )
  (block8): Block8(
    (branch0): BasicConv2d(
      (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
    (branch1): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(1792, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(192, 192, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
      (2): BasicConv2d(
        (conv): Conv2d(192, 192, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
      )
    )
    (conv2d): Conv2d(384, 1792, kernel_size=(1, 1), stride=(1, 1))
  )
  (avgpool_1a): AdaptiveAvgPool2d(output_size=1)
  (dropout): Dropout(p=0.6, inplace=False)
  (last_linear): Linear(in_features=1792, out_features=512, bias=False)
  (last_bn): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  (logits): Linear(in_features=512, out_features=1, bias=True)
)
</pre></div>
</div>
</div>
</div>
<p>The following code define a function that takes an input image and output the corresponding prediction</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">input_image</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Predict the label of the input_image&quot;&quot;&quot;</span>
    <span class="n">face</span> <span class="o">=</span> <span class="n">mtcnn</span><span class="p">(</span><span class="n">input_image</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">face</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;No face detected&quot;</span><span class="p">)</span>
    <span class="n">face</span> <span class="o">=</span> <span class="n">face</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>  <span class="c1"># add the batch dimension</span>
    <span class="n">face</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">face</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;bilinear&quot;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># convert the face into a numpy array to be able to plot it</span>
    <span class="n">prev_face</span> <span class="o">=</span> <span class="n">face</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">prev_face</span> <span class="o">=</span> <span class="n">prev_face</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;uint8&quot;</span><span class="p">)</span>

    <span class="n">face</span> <span class="o">=</span> <span class="n">face</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">face</span> <span class="o">=</span> <span class="n">face</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">face</span> <span class="o">=</span> <span class="n">face</span> <span class="o">/</span> <span class="mf">255.0</span>
    <span class="n">face_image_to_plot</span> <span class="o">=</span> <span class="n">face</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">int</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="n">target_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">block8</span><span class="o">.</span><span class="n">branch1</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">cam</span> <span class="o">=</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">target_layers</span><span class="o">=</span><span class="n">target_layers</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">ClassifierOutputTarget</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>

    <span class="n">grayscale_cam</span> <span class="o">=</span> <span class="n">cam</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">face</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">,</span> <span class="n">eigen_smooth</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">grayscale_cam</span> <span class="o">=</span> <span class="n">grayscale_cam</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">visualization</span> <span class="o">=</span> <span class="n">show_cam_on_image</span><span class="p">(</span><span class="n">face_image_to_plot</span><span class="p">,</span> <span class="n">grayscale_cam</span><span class="p">,</span> <span class="n">use_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">face_with_mask</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">addWeighted</span><span class="p">(</span><span class="n">prev_face</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">visualization</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">face</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="s2">&quot;real&quot;</span> <span class="k">if</span> <span class="n">output</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">&quot;fake&quot;</span>

        <span class="n">real_prediction</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">output</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">fake_prediction</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="n">confidences</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;real&quot;</span><span class="p">:</span> <span class="n">real_prediction</span><span class="p">,</span> <span class="s2">&quot;fake&quot;</span><span class="p">:</span> <span class="n">fake_prediction</span><span class="p">}</span>
    <span class="k">return</span> <span class="n">confidences</span><span class="p">,</span> <span class="n">prev_face</span><span class="p">,</span> <span class="n">face_with_mask</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>


<span class="k">def</span> <span class="nf">display_result</span><span class="p">(</span><span class="n">fname</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="mi">20</span> <span class="o">+</span> <span class="n">fname</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">out</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="s2">&quot;&lt;Real&gt;&quot;</span> <span class="k">if</span> <span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;real&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">&quot;&lt;Fake&gt;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted by our model: </span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s2"> [</span><span class="si">{</span><span class="n">out</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The reason of the prediction: </span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">out</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s2">&quot;examples/*&quot;</span><span class="p">):</span>
    <span class="n">display_result</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_1.png
================================================================================
</pre></div>
</div>
<img alt="../_images/b963ca4a413d7fa66dbf933bf171bbc7f8e3f162891f789f2228f4477f79a62f.png" src="../_images/b963ca4a413d7fa66dbf933bf171bbc7f8e3f162891f789f2228f4477f79a62f.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.00010454654693603516, &#39;fake&#39;: 0.999895453453064}]
</pre></div>
</div>
<img alt="../_images/42067098da7d0c6f49eb13f2c0c816e977a18b6b659173b341c31061d8268816.png" src="../_images/42067098da7d0c6f49eb13f2c0c816e977a18b6b659173b341c31061d8268816.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_3.png
================================================================================
</pre></div>
</div>
<img alt="../_images/2bb8dfa443f22a3f484ae440f146e63c8a6eeb2e18a562e07e3e8a9443eb5c30.png" src="../_images/2bb8dfa443f22a3f484ae440f146e63c8a6eeb2e18a562e07e3e8a9443eb5c30.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 5.233287811279297e-05, &#39;fake&#39;: 0.9999476671218872}]
</pre></div>
</div>
<img alt="../_images/3e5639c8844b9cc5425a1f335b10c0e457affff78bfb2c49c72175feaf6308d5.png" src="../_images/3e5639c8844b9cc5425a1f335b10c0e457affff78bfb2c49c72175feaf6308d5.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_2.png
================================================================================
</pre></div>
</div>
<img alt="../_images/f242145fab6b166c78b377fa26c0e4c83d6270f7af28f31deae8ae38eb907576.png" src="../_images/f242145fab6b166c78b377fa26c0e4c83d6270f7af28f31deae8ae38eb907576.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.00011217594146728516, &#39;fake&#39;: 0.9998878240585327}]
</pre></div>
</div>
<img alt="../_images/c6f8a30a13affc62470218a6fa9bf2d1d4d725a611dc25cd21fc015d08612df7.png" src="../_images/c6f8a30a13affc62470218a6fa9bf2d1d4d725a611dc25cd21fc015d08612df7.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_6.png
================================================================================
</pre></div>
</div>
<img alt="../_images/87c83d4684b9598ac776474e75124e0c911f5cafcdd3f7b4188ed62756670065.png" src="../_images/87c83d4684b9598ac776474e75124e0c911f5cafcdd3f7b4188ed62756670065.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.00018721818923950195, &#39;fake&#39;: 0.9998127818107605}]
</pre></div>
</div>
<img alt="../_images/06965f4851a778d04ec2c59920fe4eb3265ec4a2bcac4faa7116af1cfafd31c9.png" src="../_images/06965f4851a778d04ec2c59920fe4eb3265ec4a2bcac4faa7116af1cfafd31c9.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_7.png
================================================================================
</pre></div>
</div>
<img alt="../_images/6eebbfd7e7f72ba6c1232e319b86c5dbe2d269e728130ca3cb3358e52be4d981.png" src="../_images/6eebbfd7e7f72ba6c1232e319b86c5dbe2d269e728130ca3cb3358e52be4d981.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.00023192167282104492, &#39;fake&#39;: 0.999768078327179}]
</pre></div>
</div>
<img alt="../_images/e00af54033d8ad7ba62cef2ebfb62430620df069cf56b8f84de22fbb7ec23e1a.png" src="../_images/e00af54033d8ad7ba62cef2ebfb62430620df069cf56b8f84de22fbb7ec23e1a.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_5.png
================================================================================
</pre></div>
</div>
<img alt="../_images/53592f300c96ffc980ff750d68d162a7ba4b66e24e48a3736210112352f47802.png" src="../_images/53592f300c96ffc980ff750d68d162a7ba4b66e24e48a3736210112352f47802.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.00187760591506958, &#39;fake&#39;: 0.9981223940849304}]
</pre></div>
</div>
<img alt="../_images/2d09ec241153fc4db1dc8f75d803c7cbecbce3011c731a14193f7b2811f64445.png" src="../_images/2d09ec241153fc4db1dc8f75d803c7cbecbce3011c731a14193f7b2811f64445.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_mercedes.jpeg
================================================================================
</pre></div>
</div>
<img alt="../_images/432e95dded0cf53833f7af59edba82e0475c28c79722e42c40ef9db4bb8585da.png" src="../_images/432e95dded0cf53833f7af59edba82e0475c28c79722e42c40ef9db4bb8585da.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.8550797253847122, &#39;fake&#39;: 0.14492027461528778}]
</pre></div>
</div>
<img alt="../_images/add3a23082baa0b9df3aab72b4cc141e80a86bae939e79c0dbe93e7c7177b53d.png" src="../_images/add3a23082baa0b9df3aab72b4cc141e80a86bae939e79c0dbe93e7c7177b53d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_4.png
================================================================================
</pre></div>
</div>
<img alt="../_images/e1e8c28c15b716abc96329cd06b65d96c26bf8ca11f1cc401abdf81f49efced4.png" src="../_images/e1e8c28c15b716abc96329cd06b65d96c26bf8ca11f1cc401abdf81f49efced4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.21064341068267822, &#39;fake&#39;: 0.7893565893173218}]
</pre></div>
</div>
<img alt="../_images/a27610f0244350eb7f2efc4079552a430a877c2b92f55160ff919ff8a7ad653c.png" src="../_images/a27610f0244350eb7f2efc4079552a430a877c2b92f55160ff919ff8a7ad653c.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_19.png
================================================================================
</pre></div>
</div>
<img alt="../_images/a5e326414b9460ee75867aac3bebfc042962bd10c9fcc01bfbdb8d9698e0e1e9.png" src="../_images/a5e326414b9460ee75867aac3bebfc042962bd10c9fcc01bfbdb8d9698e0e1e9.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.9999999760254799, &#39;fake&#39;: 2.3974520146907707e-08}]
</pre></div>
</div>
<img alt="../_images/0ab06c88d7703512b7ae16a1381b5e6ba3cf3e0b4e430bf50aa567c328596c2d.png" src="../_images/0ab06c88d7703512b7ae16a1381b5e6ba3cf3e0b4e430bf50aa567c328596c2d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_15.png
================================================================================
</pre></div>
</div>
<img alt="../_images/2d13b9772800b6506a76ff9bc4e155708a0d83ab7b199e5672f57f6f6f8bc356.png" src="../_images/2d13b9772800b6506a76ff9bc4e155708a0d83ab7b199e5672f57f6f6f8bc356.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.001075446605682373, &#39;fake&#39;: 0.9989245533943176}]
</pre></div>
</div>
<img alt="../_images/53c5018adb3eba547e60ac5be149c1f25c4762e1d7876735292a174476da8a54.png" src="../_images/53c5018adb3eba547e60ac5be149c1f25c4762e1d7876735292a174476da8a54.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_9.png
================================================================================
</pre></div>
</div>
<img alt="../_images/3de838ce59582f2bd900fd2f4856a01beaf7a8730bccb6164b48b6cefad7151b.png" src="../_images/3de838ce59582f2bd900fd2f4856a01beaf7a8730bccb6164b48b6cefad7151b.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.9999986545436741, &#39;fake&#39;: 1.3454563259074348e-06}]
</pre></div>
</div>
<img alt="../_images/db835f08bf1efe769a5bfb8786c63acb21d650e7b7d86ed2df2e98587cad94ea.png" src="../_images/db835f08bf1efe769a5bfb8786c63acb21d650e7b7d86ed2df2e98587cad94ea.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_lucia.jpeg
================================================================================
</pre></div>
</div>
<img alt="../_images/f3ef1c61ff3b8c9597654f85b543352caa1db4ac714a9972ba6f3d1835ccc94e.png" src="../_images/f3ef1c61ff3b8c9597654f85b543352caa1db4ac714a9972ba6f3d1835ccc94e.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.9999999977415401, &#39;fake&#39;: 2.2584598635688735e-09}]
</pre></div>
</div>
<img alt="../_images/3118976809ed745c26ec4b3e67f386215714bd8d0aef5fc20fe2d4c3d66d7811.png" src="../_images/3118976809ed745c26ec4b3e67f386215714bd8d0aef5fc20fe2d4c3d66d7811.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_17.png
================================================================================
</pre></div>
</div>
<img alt="../_images/25bfe982b7638391fe79de3b2d961277ee329db0f941822c13bcc63eca861486.png" src="../_images/25bfe982b7638391fe79de3b2d961277ee329db0f941822c13bcc63eca861486.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 2.384185791015625e-07, &#39;fake&#39;: 0.9999997615814209}]
</pre></div>
</div>
<img alt="../_images/e1bfe582e687e1ae7218ea5ce057002aed20010c7b48031f0ad814cb7dc37dbe.png" src="../_images/e1bfe582e687e1ae7218ea5ce057002aed20010c7b48031f0ad814cb7dc37dbe.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_16.png
================================================================================
</pre></div>
</div>
<img alt="../_images/f10f6436428c665bc897d78afad2fb03b1c45083b50c921fa5bdcd541e1beb83.png" src="../_images/f10f6436428c665bc897d78afad2fb03b1c45083b50c921fa5bdcd541e1beb83.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.07662761211395264, &#39;fake&#39;: 0.9233723878860474}]
</pre></div>
</div>
<img alt="../_images/2a95b27d06a6b1ad257932bae4dc9cc0571c7cfe34653b0c9ff681c3d49550a1.png" src="../_images/2a95b27d06a6b1ad257932bae4dc9cc0571c7cfe34653b0c9ff681c3d49550a1.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_8.png
================================================================================
</pre></div>
</div>
<img alt="../_images/21e509c282e030eefb5a286da7b263a14b8c930ff403fee23b588cbf253a432d.png" src="../_images/21e509c282e030eefb5a286da7b263a14b8c930ff403fee23b588cbf253a432d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.9999997878268374, &#39;fake&#39;: 2.1217316259480867e-07}]
</pre></div>
</div>
<img alt="../_images/f696b482502332429654513502c127120f1c32ea0192c5dc156d5608b0dbe826.png" src="../_images/f696b482502332429654513502c127120f1c32ea0192c5dc156d5608b0dbe826.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_12.png
================================================================================
</pre></div>
</div>
<img alt="../_images/df90b620fe40ef06d640934af7540b47fcce1da78027e037935e530aa44d9f27.png" src="../_images/df90b620fe40ef06d640934af7540b47fcce1da78027e037935e530aa44d9f27.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 1.4781951904296875e-05, &#39;fake&#39;: 0.9999852180480957}]
</pre></div>
</div>
<img alt="../_images/8a29551d51fb5a957ecdf1a4e3c72869c7b502b794042432fd6c5664f6e026f9.png" src="../_images/8a29551d51fb5a957ecdf1a4e3c72869c7b502b794042432fd6c5664f6e026f9.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_13.png
================================================================================
</pre></div>
</div>
<img alt="../_images/481cb3afa6b90418904d918556addd61367d6a0a13abcdc935e4aaa50231d3b1.png" src="../_images/481cb3afa6b90418904d918556addd61367d6a0a13abcdc935e4aaa50231d3b1.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.00046050548553466797, &#39;fake&#39;: 0.9995394945144653}]
</pre></div>
</div>
<img alt="../_images/57d72b4587c96b77efd6880263a90966be4874b45f2083b65497dfd4cc1f0208.png" src="../_images/57d72b4587c96b77efd6880263a90966be4874b45f2083b65497dfd4cc1f0208.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_20.png
================================================================================
</pre></div>
</div>
<img alt="../_images/c867a4429b7b073113f5ec16ff3272c724a8498f06f4f2feeabd8314ff9f2a8b.png" src="../_images/c867a4429b7b073113f5ec16ff3272c724a8498f06f4f2feeabd8314ff9f2a8b.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.9999540159587923, &#39;fake&#39;: 4.598404120770283e-05}]
</pre></div>
</div>
<img alt="../_images/16068aa8c2fb000a33e2f993f44b85ff108a5e4e8e947155c699d1fdc26b8da6.png" src="../_images/16068aa8c2fb000a33e2f993f44b85ff108a5e4e8e947155c699d1fdc26b8da6.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_11.png
================================================================================
</pre></div>
</div>
<img alt="../_images/6229828cce2a5c07f061961c56d7572f418396447f5629831c0d2e43807e9978.png" src="../_images/6229828cce2a5c07f061961c56d7572f418396447f5629831c0d2e43807e9978.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.014934957027435303, &#39;fake&#39;: 0.9850650429725647}]
</pre></div>
</div>
<img alt="../_images/c5de5af20ce19210a165adc0cc229452b53d9831b82bf81512af7f76004706d7.png" src="../_images/c5de5af20ce19210a165adc0cc229452b53d9831b82bf81512af7f76004706d7.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_10.png
================================================================================
</pre></div>
</div>
<img alt="../_images/f119cf45e315c95bfdf64e33383e60a24427754c75f3eb2a0ba70f6dc8cd2458.png" src="../_images/f119cf45e315c95bfdf64e33383e60a24427754c75f3eb2a0ba70f6dc8cd2458.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 4.00543212890625e-05, &#39;fake&#39;: 0.9999599456787109}]
</pre></div>
</div>
<img alt="../_images/9b88dea64acb1c32cf91fad1c7eb67547db185977c0b871adb12faf3d5f3d7b4.png" src="../_images/9b88dea64acb1c32cf91fad1c7eb67547db185977c0b871adb12faf3d5f3d7b4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_3.png
================================================================================
</pre></div>
</div>
<img alt="../_images/b7b628cf9dd4e4727f338dee42311f2666b807100a3f3e69096b7c6a6e56f728.png" src="../_images/b7b628cf9dd4e4727f338dee42311f2666b807100a3f3e69096b7c6a6e56f728.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.9999999934243937, &#39;fake&#39;: 6.575606281700175e-09}]
</pre></div>
</div>
<img alt="../_images/91330918608f6733fc238bad55e03dd049a2f21587d61b6960e68209de8d9255.png" src="../_images/91330918608f6733fc238bad55e03dd049a2f21587d61b6960e68209de8d9255.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_20.png
================================================================================
</pre></div>
</div>
<img alt="../_images/295a0ebe9c4fe61f0c837b5e520660980668cf4d4e045dfae62775205dbd4f7b.png" src="../_images/295a0ebe9c4fe61f0c837b5e520660980668cf4d4e045dfae62775205dbd4f7b.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 5.030632019042969e-05, &#39;fake&#39;: 0.9999496936798096}]
</pre></div>
</div>
<img alt="../_images/97c021df35c064cfe4ff673547612695048bff352c6138488b0a6554414af5ef.png" src="../_images/97c021df35c064cfe4ff673547612695048bff352c6138488b0a6554414af5ef.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_2.png
================================================================================
</pre></div>
</div>
<img alt="../_images/53ecf2cbffdf5c281ea601d7b70ff9c52f38464b52eec7cfc4a900f96373ea96.png" src="../_images/53ecf2cbffdf5c281ea601d7b70ff9c52f38464b52eec7cfc4a900f96373ea96.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.03622013330459595, &#39;fake&#39;: 0.963779866695404}]
</pre></div>
</div>
<img alt="../_images/3b0aa418f4f9b27fa229f582a1b93b5decf659a6f1f4decacd3b7a08d0da5bda.png" src="../_images/3b0aa418f4f9b27fa229f582a1b93b5decf659a6f1f4decacd3b7a08d0da5bda.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_13.png
================================================================================
</pre></div>
</div>
<img alt="../_images/d844a1774df5779cf4165bd6882d0832376466e1eda5f85f4469e855d8fdb860.png" src="../_images/d844a1774df5779cf4165bd6882d0832376466e1eda5f85f4469e855d8fdb860.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.9992852220311761, &#39;fake&#39;: 0.0007147779688239098}]
</pre></div>
</div>
<img alt="../_images/f0ee9f9dbf095a0f872ac31dd410aa5eecb863533041ddda752c8c45f22c3a98.png" src="../_images/f0ee9f9dbf095a0f872ac31dd410aa5eecb863533041ddda752c8c45f22c3a98.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_1.png
================================================================================
</pre></div>
</div>
<img alt="../_images/62b8105b95b38e1c04bee1aae18b2d89d0477c68a755e4638d321b6b3da3679d.png" src="../_images/62b8105b95b38e1c04bee1aae18b2d89d0477c68a755e4638d321b6b3da3679d.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.9999886736432018, &#39;fake&#39;: 1.1326356798235793e-05}]
</pre></div>
</div>
<img alt="../_images/fdd1bd8d9cad456868ed1aeb15482038406fd3162147d98be7424d2f384131df.png" src="../_images/fdd1bd8d9cad456868ed1aeb15482038406fd3162147d98be7424d2f384131df.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_16.png
================================================================================
</pre></div>
</div>
<img alt="../_images/a95661e1ee97c4ec908cd9ecd1e800196076d2e1b05e743165a806d05dff12ae.png" src="../_images/a95661e1ee97c4ec908cd9ecd1e800196076d2e1b05e743165a806d05dff12ae.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.987897539511323, &#39;fake&#39;: 0.012102460488677025}]
</pre></div>
</div>
<img alt="../_images/1918fe9276c7433864d35a86647eac7cdb0ff776693f780697d9d38960c8df43.png" src="../_images/1918fe9276c7433864d35a86647eac7cdb0ff776693f780697d9d38960c8df43.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/real_frame_15.png
================================================================================
</pre></div>
</div>
<img alt="../_images/adfbefcee1cf4e53983b8703c5b1182613154a979eccf3f98e3b8728f9197657.png" src="../_images/adfbefcee1cf4e53983b8703c5b1182613154a979eccf3f98e3b8728f9197657.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.5079668760299683, &#39;fake&#39;: 0.49203312397003174}]
</pre></div>
</div>
<img alt="../_images/971a0171264827df1ede19e3d0e4e723dc29797bc8075c49192036fc93b1bf5b.png" src="../_images/971a0171264827df1ede19e3d0e4e723dc29797bc8075c49192036fc93b1bf5b.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_19.png
================================================================================
</pre></div>
</div>
<img alt="../_images/8b2fbba3501683039b43d6821983048e5033cd5b9a1ea4974a8ccbceaa38c34b.png" src="../_images/8b2fbba3501683039b43d6821983048e5033cd5b9a1ea4974a8ccbceaa38c34b.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 4.172325134277344e-06, &#39;fake&#39;: 0.9999958276748657}]
</pre></div>
</div>
<img alt="../_images/bcc03812a31d6261bdf3698d0ab4c29c191f7796273b6f741548c5a6186f0d31.png" src="../_images/bcc03812a31d6261bdf3698d0ab4c29c191f7796273b6f741548c5a6186f0d31.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_9.png
================================================================================
</pre></div>
</div>
<img alt="../_images/ef59f8024f308333e9787f8d7c78efc54d822a7f9beb36576b4eeb89cc6fe6e9.png" src="../_images/ef59f8024f308333e9787f8d7c78efc54d822a7f9beb36576b4eeb89cc6fe6e9.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 4.291534423828125e-06, &#39;fake&#39;: 0.9999957084655762}]
</pre></div>
</div>
<img alt="../_images/71b6bcc65c17155cbe9de9887e977c80cf278dd40eac65e1ac3ecf0469d9784f.png" src="../_images/71b6bcc65c17155cbe9de9887e977c80cf278dd40eac65e1ac3ecf0469d9784f.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_dot_csv.jpeg
================================================================================
</pre></div>
</div>
<img alt="../_images/6f0d240d4cc067d4ef9568cf1efe8d198b1d66f765a7a68ba1b0edcea8b0bde4.png" src="../_images/6f0d240d4cc067d4ef9568cf1efe8d198b1d66f765a7a68ba1b0edcea8b0bde4.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.025828897953033447, &#39;fake&#39;: 0.9741711020469666}]
</pre></div>
</div>
<img alt="../_images/762165619ff3309e84f0c7fb424eba5e8786f4da82eff7186cd1f10394bc51d6.png" src="../_images/762165619ff3309e84f0c7fb424eba5e8786f4da82eff7186cd1f10394bc51d6.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    examples/fake_frame_8.png
================================================================================
</pre></div>
</div>
<img alt="../_images/56cf26f3259c6e93c1e8f534f44f818ae41ab7738346c3de963e100ec53b9944.png" src="../_images/56cf26f3259c6e93c1e8f534f44f818ae41ab7738346c3de963e100ec53b9944.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.0, &#39;fake&#39;: 1.0}]
</pre></div>
</div>
<img alt="../_images/10689662a2333786785a7b1ad24bd1d64422e51cee82fffc2f725543fc18971e.png" src="../_images/10689662a2333786785a7b1ad24bd1d64422e51cee82fffc2f725543fc18971e.png" />
</div>
</div>
</section>
<section id="let-s-try-some-images-from-popular-meme">
<h3>Let’s try some images from popular meme<a class="headerlink" href="#let-s-try-some-images-from-popular-meme" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget<span class="w"> </span>https://i.ytimg.com/vi/wu-lMi1nw9s/maxresdefault.jpg<span class="w"> </span>-O<span class="w"> </span>starwar1.jpg
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
--2024-02-09 19:13:05--  https://i.ytimg.com/vi/wu-lMi1nw9s/maxresdefault.jpg
Loaded CA certificate &#39;/etc/ssl/certs/ca-certificates.crt&#39;
Resolving i.ytimg.com (i.ytimg.com)... 172.217.167.86, 142.250.66.246, 142.250.76.118, ...
Connecting to i.ytimg.com (i.ytimg.com)|172.217.167.86|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 74326 (73K) [image/jpeg]
Saving to: ‘starwar1.jpg’

starwar1.jpg        100%[===================&gt;]  72.58K  --.-KB/s    in 0.05s   

2024-02-09 19:13:06 (1.53 MB/s) - ‘starwar1.jpg’ saved [74326/74326]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_result</span><span class="p">(</span><span class="s2">&quot;starwar1.jpg&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    starwar1.jpg
================================================================================
</pre></div>
</div>
<img alt="../_images/6be13d4c87f8727e0dd0ed4e994a32d1e4398a93f6322c377601b158bfb4efd6.png" src="../_images/6be13d4c87f8727e0dd0ed4e994a32d1e4398a93f6322c377601b158bfb4efd6.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Real&gt; [{&#39;real&#39;: 0.9961821485776454, &#39;fake&#39;: 0.003817851422354579}]
</pre></div>
</div>
<img alt="../_images/d54d083a7687f431c81cf8cc4ba50fa0b8195fcfb8daa85423e7fe9adc864908.png" src="../_images/d54d083a7687f431c81cf8cc4ba50fa0b8195fcfb8daa85423e7fe9adc864908.png" />
</div>
</div>
<p><strong>Now, here comes a fake one</strong></p>
<p>Starring, <em>Nicolas Cage</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget<span class="w"> </span>https://pbs.twimg.com/media/EKi1flkXYAA5-A_?format<span class="o">=</span>jpg<span class="w"> </span>-O<span class="w"> </span>starwar2.jpg
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
--2024-02-09 19:13:06--  https://pbs.twimg.com/media/EKi1flkXYAA5-A_?format=jpg
Loaded CA certificate &#39;/etc/ssl/certs/ca-certificates.crt&#39;
Resolving pbs.twimg.com (pbs.twimg.com)... 117.18.237.70, 2606:2800:248:1347:709:24f:182c:618
Connecting to pbs.twimg.com (pbs.twimg.com)|117.18.237.70|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 50381 (49K) [image/jpeg]
Saving to: ‘starwar2.jpg’

starwar2.jpg        100%[===================&gt;]  49.20K  --.-KB/s    in 0.02s   

2024-02-09 19:13:07 (2.40 MB/s) - ‘starwar2.jpg’ saved [50381/50381]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_result</span><span class="p">(</span><span class="s2">&quot;starwar2.jpg&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>================================================================================
                    starwar2.jpg
================================================================================
</pre></div>
</div>
<img alt="../_images/d48d86cd581d9de8fa2db0648ca47972661562b1af4a718223956aabb12acf67.png" src="../_images/d48d86cd581d9de8fa2db0648ca47972661562b1af4a718223956aabb12acf67.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predicted by our model: &lt;Fake&gt; [{&#39;real&#39;: 0.0038504600524902344, &#39;fake&#39;: 0.9961495399475098}]
</pre></div>
</div>
<img alt="../_images/f23c89915c29da807b1c3266e27c3581a9fee9fbe7c05d770325faf8ad5464b1.png" src="../_images/f23c89915c29da807b1c3266e27c3581a9fee9fbe7c05d770325faf8ad5464b1.png" />
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Module_5_Anomaly_and_Intrusion_Detection_with_Machine_Learning.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>Module 5:</strong> Anomaly and Intrusion Detection with Machine Learning</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tunning-a-model-for-cyber-security">Fine-tunning a model for Cyber Security</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#case-study-securebret">Case Study: SecureBret</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-llms-as-offensive-generative-ai">Using LLMs as Offensive Generative AI</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#offensive-generative-ai-model">Offensive Generative AI Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-model-for-cracking-password">Generative model for cracking password</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#passgpt">PassGPT</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-the-behaviour-of-human-s-password-creation">Learning the behaviour of human’s password creation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-password-generation">Conditional Password Generation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#defensive-generative-ai">Defensive Generative AI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#detecting-deepfake">Detecting Deepfake</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#let-s-try-some-images-from-popular-meme">Let’s try some images from popular meme</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By WSU Staffs
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>